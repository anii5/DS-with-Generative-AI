{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is the role of filters and feature maps in Convolutional Neural Network (CNN)?\n",
        "  - In a Convolutional Neural Network (CNN), filters and feature maps are the primary components that allow the model to \"see\" and interpret visual data. While they work together, they represent different stages of the process: one is the tool, and the other is the result.\n",
        "      - Filters (The Tools)\n",
        "A filter (also called a kernel) is a small matrix of weights that slides across the input image. Think of it as a specialized lens designed to look for a specific pattern.\n",
        "      - Feature Maps (The Results)\n",
        "A feature map is the output produced by applying a filter to the input. If the filter is the \"detector,\" the feature map is the \"detection report.\""
      ],
      "metadata": {
        "id": "DWI1abBQmnE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Explain the concepts of padding and stride in CNNs(Convolutional Neural Network). How do they affect the output dimensions of feature maps?\n",
        "  - In Convolutional Neural Networks, Stride and Padding are the \"control knobs\" that determine how a filter traverses an image and, consequently, what the size of the resulting feature map will be.\n",
        "      - Stride (The Step Size)\n",
        "Stride defines the number of pixels the filter moves (shifts) at each step as it scans the input image.\n",
        "      - Padding (The Border)\n",
        "Padding involves adding extra \"dummy\" pixels (usually zeros, called Zero Padding) around the outer edges of the input image before the convolution begins.\n",
        "      - Impact on Output DimensionsThe relationship between input size, filter size, stride, and padding is governed by a specific mathematical formula.If we have:\n",
        "          - Input size ($W$)\n",
        "          - Filter/Kernel size ($K$)\n",
        "          - Padding ($P$)\n",
        "          - Stride ($S$)\n",
        "          - The Output Width ($O$) is calculated as:$$O = \\left\\lfloor \\frac{W - K + 2P}{S} \\right\\rfloor + 1$$"
      ],
      "metadata": {
        "id": "ZYIZe88um5jC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define receptive field in the context of CNNs. Why is it important for deep architectures?\n",
        "  - In the context of Convolutional Neural Networks (CNNs), the Receptive Field (RF) is the specific region of the input image that a particular feature in a layer is \"looking at.\"While a single pixel in the first layer only sees a tiny $3 \\times 3$ or $5 \\times 5$ patch of the original image, a pixel in a much deeper layer might have a receptive field that covers the entire input.\n",
        "  - The receptive field is essentially the \"context\" available to a neuron. Its size determines what kind of features the network can learn:\n",
        "\n",
        "      - Small Receptive Field (Early Layers): The network can only see low-level details like edges, dots, or tiny textures. It’s like looking at a painting through a drinking straw; you can see the brushstrokes, but you don't know what the subject is.\n",
        "\n",
        "      - Large Receptive Field (Deep Layers): The network can see the \"big picture.\" To recognize a \"dog,\" the network needs a receptive field large enough to encompass the ears, nose, tail, and legs simultaneously to understand their spatial relationship."
      ],
      "metadata": {
        "id": "HqI9J5CxpHPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Discuss how filter size and stride influence the number of parameters in a CNN.\n",
        "  - 1. The filter size (or kernel size) has a direct, linear relationship with the number of parameters.Each filter consists of a grid of weights. If you have a filter of size $K \\times K$ and an input with $C$ channels (e.g., 3 for RGB), the number of parameters for that one filter is:$$\\text{Parameters per Filter} = (K \\times K \\times C) + 1 \\text{ (bias)}$$\n",
        "  - 2. The stride has zero impact on the number of parameters in a specific convolutional layer.Why? Stride only dictates the movement of the filter. Whether a $3 \\times 3$ filter moves 1 pixel at a time or jumps 10 pixels at a time, it still only possesses 9 weights (plus a bias).The Indirect Effect: While stride doesn't change the parameters of the current layer, it drastically reduces the output feature map size."
      ],
      "metadata": {
        "id": "xNyB-XtYqcsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Compare and contrast different CNN-based architectures like LeNet, AlexNet, and VGG in terms of depth, filter sizes, and performance.\n",
        "  - LeNet was designed for simple grayscale images ($32 \\times 32$). It established the core \"Conv-Pool-Conv-Pool-FC\" pattern used today.\n",
        "  - AlexNet scaled up the CNN concept for the ImageNet challenge ($224 \\times 224$ images), utilizing GPUs for the first time.\n",
        "  - VGG moved away from the \"large filter\" approach of AlexNet. Instead of trying to see a lot at once with an $11 \\times 11$ filter, it used stacks of $3 \\times 3$ filters."
      ],
      "metadata": {
        "id": "rf3mPny6r_kZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Using keras, build and train a simple CNN model on the MNIST dataset from scratch. Include code for module creation, compilation, training, and evaluation."
      ],
      "metadata": {
        "id": "X78bkQpew0DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras import backend as k\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "img_rows, img_cols=28, 28\n",
        "\n",
        "if k.image_data_format() == 'channels_first':\n",
        "   x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "   x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "   inpx = (1, img_rows, img_cols)\n",
        "\n",
        "else:\n",
        "   x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "   x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "   inpx = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "inpx = Input(shape=inpx)\n",
        "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx)\n",
        "layer2 = Conv2D(64, (3, 3), activation='relu')(layer1)\n",
        "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
        "layer4 = Dropout(0.5)(layer3)\n",
        "layer5 = Flatten()(layer4)\n",
        "layer6 = Dense(250, activation='sigmoid')(layer5)\n",
        "layer7 = Dense(10, activation='softmax')(layer6)\n",
        "model = Model([inpx], layer7)\n",
        "model.compile(optimizer=keras.optimizers.Adadelta(),\n",
        "              loss=keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=12, batch_size=500)\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('loss=', score[0])\n",
        "print('accuracy=', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdB_IqAww5WA",
        "outputId": "88f9d231-37e2-4a72-e132-648fa0fae34d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 803ms/step - accuracy: 0.1021 - loss: 2.4609\n",
            "Epoch 2/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 791ms/step - accuracy: 0.1019 - loss: 2.4424\n",
            "Epoch 3/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 770ms/step - accuracy: 0.1024 - loss: 2.4237\n",
            "Epoch 4/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 819ms/step - accuracy: 0.1036 - loss: 2.4066\n",
            "Epoch 5/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 771ms/step - accuracy: 0.1010 - loss: 2.3926\n",
            "Epoch 6/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 787ms/step - accuracy: 0.1025 - loss: 2.3760\n",
            "Epoch 7/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 740ms/step - accuracy: 0.1022 - loss: 2.3615\n",
            "Epoch 8/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 742ms/step - accuracy: 0.1018 - loss: 2.3496\n",
            "Epoch 9/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 791ms/step - accuracy: 0.1027 - loss: 2.3351\n",
            "Epoch 10/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 755ms/step - accuracy: 0.1026 - loss: 2.3202\n",
            "Epoch 11/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 748ms/step - accuracy: 0.1012 - loss: 2.3093\n",
            "Epoch 12/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 748ms/step - accuracy: 0.1023 - loss: 2.2956\n",
            "loss= 2.2871527671813965\n",
            "accuracy= 0.10100000351667404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  Load and preprocess the CIFAR-10 dataset using Keras, and create a CNN model to classify RGB images. Show your preprocessing and architecture."
      ],
      "metadata": {
        "id": "zNWLqW3Tz4tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# 2. Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define class names for visualization later\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "model = models.Sequential([\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    # Flattening and Dense Layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10) # 10 output units for 10 classes\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "idNVkS3Z0Mmw",
        "outputId": "779ee534-b309-43c9-d34b-37a30c086b82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m65,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m122,570\u001b[0m (478.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,570</span> (478.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,570\u001b[0m (478.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,570</span> (478.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 32ms/step - accuracy: 0.3415 - loss: 1.7671 - val_accuracy: 0.5343 - val_loss: 1.2909\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 31ms/step - accuracy: 0.5542 - loss: 1.2442 - val_accuracy: 0.5964 - val_loss: 1.1287\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 31ms/step - accuracy: 0.6205 - loss: 1.0755 - val_accuracy: 0.6222 - val_loss: 1.0705\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 31ms/step - accuracy: 0.6581 - loss: 0.9699 - val_accuracy: 0.6567 - val_loss: 0.9989\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 31ms/step - accuracy: 0.6913 - loss: 0.8838 - val_accuracy: 0.6851 - val_loss: 0.9111\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 31ms/step - accuracy: 0.7094 - loss: 0.8256 - val_accuracy: 0.6974 - val_loss: 0.8842\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 32ms/step - accuracy: 0.7341 - loss: 0.7594 - val_accuracy: 0.6843 - val_loss: 0.9078\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 31ms/step - accuracy: 0.7420 - loss: 0.7291 - val_accuracy: 0.7096 - val_loss: 0.8562\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 32ms/step - accuracy: 0.7604 - loss: 0.6775 - val_accuracy: 0.7041 - val_loss: 0.8807\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 33ms/step - accuracy: 0.7736 - loss: 0.6443 - val_accuracy: 0.7037 - val_loss: 0.8918\n",
            "313/313 - 3s - 9ms/step - accuracy: 0.7037 - loss: 0.8918\n",
            "\n",
            "Test accuracy: 0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Using PyTorch, write a script to define and train a CNN on the MNIST dataset. Include model definition, data loaders, training loop, and accuracy evaluation."
      ],
      "metadata": {
        "id": "1s9F0RClz803"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def load_mnist(batch_size=5):\n",
        "    transform = transforms.ToTensor()\n",
        "    dataset = datasets.MNIST(\n",
        "        root=\"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "def visualize_samples(dataloader, num_samples=5):\n",
        "    images, labels = next(iter(dataloader))\n",
        "\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        plt.imshow(images[i].squeeze(), cmap=\"gray\")\n",
        "        plt.title(f\"Label: {labels[i].item()}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "train_loader = load_mnist(batch_size=5)\n",
        "visualize_samples(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "XG0M-XVU0NQ3",
        "outputId": "9b11a90e-7b44-4905-8218-a92b9a7cc6f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.93MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 165kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.56MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.68MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}